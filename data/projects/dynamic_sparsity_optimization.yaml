title: Dynamic Sparsity Optimization for CNNs
slug: dynamic-sparsity-optimization
description: Designed and implemented a 5-stage, compiler-aware model compression and deployment pipeline for CNNs, inspired by IR/MLIR-style transformations. The system progressively transforms models from dense to sparse to fused to compressed to ONNX-deployable forms, preserving structured sparsity and accuracy at each stage for efficient deployment.
role: Lead Researcher
technologies:
  - PyTorch 2.6.0+cu124
  - CUDA 12.3
  - NVIDIA GeForce GTX 1080 Ti (11264 MiB)
  - Convolutional Neural Networks (CNNs)
  - RigL Sparse Training
  - Grad-CAM Structured Pruning (30% conv1 filter pruning)
  - CSR/COO Sparse Formats
  - FP16 Quantization
  - ONNX Runtime
  - Model Compression
  - Compiler-Inspired Optimization
methods:
  - MLIR-inspired, modular pipeline with progressive IR-style passes
  - 5-stage transformation: Dense → Sparse → Fused → Compressed → ONNX
  - Grad-CAM computed once before training using test set for feature importance
  - Adaptive sparsity scheduling (5% increments when accuracy stable)
  - Operator fusion and format conversion for ONNX compatibility
  - Comprehensive ablation study across all pipeline stages
  - Real-time monitoring of sparsity, FLOPs, and memory during training
results: 
  - Achieved 98.98% sparsity on LeNet-5 (MNIST) and 91.21% sparsity on VGG-11 (CIFAR-10)
  - 60.37% model compression with maintained accuracy
  - 4.33× inference speedup with ONNX optimization
impact: "Demonstrates a compiler-aware compression framework for efficient CNN deployment on resource-constrained environments"
duration: "12 months"
team_size: 1
challenges: "Integrating pruning, quantization, and graph-level operator fusion while maintaining accuracy; preserving structured sparsity through all transformation stages; conducting rigorous ablation study to measure impact of each pipeline stage; ensuring Grad-CAM-guided pruning doesn't compromise model performance."
created_at: '2025-01-27T10:00:00.000000'
sections: ["research", "project"]
relevance_tags: ["ml", "optimization", "sparsity", "gpu", "cuda", "computer-vision", "research", "edge-ai", "onnx", "deployment", "compression", "compiler"]
featured: true
source_text: "I led research on dynamic sparsity optimization for CNNs using NVIDIA GeForce GTX 1080 Ti and PyTorch 2.6.0+cu124 with CUDA 12.3. I architected a 5-stage, MLIR-inspired compression and deployment pipeline: (1) dense baseline, (2) RigL-based sparse training with Grad-CAM-guided pruning (computed once before training), (3) BatchNorm fusion for operator reduction, (4) compression using CSR/COO sparse formats and FP16 storage, and (5) ONNX export and deployment with structure-preserving transformations. The pipeline achieved 98.98% sparsity for LeNet-5 and 91.21% sparsity for VGG-11, with 60.37% model compression and maintained or improved accuracy across all stages. Each stage was validated via ablation analysis, establishing a reproducible, compiler-aware path to efficient deep learning deployment."
filename: dynamic_sparsity_optimization